import{_ as e,c as i,a as n,o as s}from"./app-D9oilhFN.js";const r={};function t(l,a){return s(),i("div",null,[...a[0]||(a[0]=[n(`<h2 id="overview" tabindex="-1"><a class="header-anchor" href="#overview"><span>Overview</span></a></h2><p>DataFlex is an advanced dynamic training framework built on <a href="https://github.com/hiyouga/LLaMA-Factory" target="_blank" rel="noopener noreferrer">LlamaFactory</a>. It intelligently schedules data during training, supporting <strong>dynamic sample selection</strong>, <strong>domain ratio adjustment</strong>, and <strong>dynamic weight allocation</strong> to improve training efficiency and final model performance.</p><h3 id="design-philosophy" tabindex="-1"><a class="header-anchor" href="#design-philosophy"><span>Design Philosophy</span></a></h3><p>The core design philosophy of DataFlex is: <strong>Data-centric intelligent training scheduling</strong>. Traditional training methods typically use fixed data order and ratios, while DataFlex allows models to dynamically adjust data usage strategies based on their current state during training, achieving more efficient learning. It is designed to seamlessly integrate with LlamaFactory, providing researchers and developers with more flexible and powerful training control capabilities.</p><h2 id="core-architecture" tabindex="-1"><a class="header-anchor" href="#core-architecture"><span>Core Architecture</span></a></h2><h3 id="overall-architecture-diagram" tabindex="-1"><a class="header-anchor" href="#overall-architecture-diagram"><span>Overall Architecture Diagram</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-"><span class="line"><span>┌─────────────────────────────────────────────────────────────┐</span></span>
<span class="line"><span>│                      LlamaFactory Framework                 │</span></span>
<span class="line"><span>├─────────────────────────────────────────────────────────────┤</span></span>
<span class="line"><span>│         Model Management · Data Processing · Optimizers     │</span></span>
<span class="line"><span>├─────────────────────────────────────────────────────────────┤</span></span>
<span class="line"><span>│                                                             │</span></span>
<span class="line"><span>│    Training Layer (DataFlex replaces LlamaFactory trainer)  │</span></span>
<span class="line"><span>│  ┌─────────────────┬─────────────────┬─────────────────────┐ │</span></span>
<span class="line"><span>│  │  Select Trainer │   Mix Trainer   │  Weight Trainer     │ │</span></span>
<span class="line"><span>│  │ (Dynamic Sample │  (Dynamic Ratio)│ (Dynamic Weights)   │ │</span></span>
<span class="line"><span>│  │   Selection)    │                 │                     │ │</span></span>
<span class="line"><span>│  ├─────────────────┼─────────────────┼─────────────────────┤ │</span></span>
<span class="line"><span>│  │ Selector Components│ Mixer Components│ Weighter Components│ │</span></span>
<span class="line"><span>│  │ ┌─────────────┐ │ ┌─────────────┐ │ ┌─────────────────┐ │ │</span></span>
<span class="line"><span>│  │ │Loss Selector│ │ │Random Mixer │ │ │ Loss Weighter   │ │ │</span></span>
<span class="line"><span>│  │ │LESS Selector│ │ │Custom Mixer │ │ │ Custom Weighter │ │ │</span></span>
<span class="line"><span>│  │ │ Custom...   │ │ │   ...       │ │ │    ...          │ │ │</span></span>
<span class="line"><span>│  │ └─────────────┘ │ └─────────────┘ │ └─────────────────┘ │ │</span></span>
<span class="line"><span>│  └─────────────────┴─────────────────┴─────────────────────┘ │</span></span>
<span class="line"><span>└─────────────────────────────────────────────────────────────┘</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="component-hierarchy" tabindex="-1"><a class="header-anchor" href="#component-hierarchy"><span>Component Hierarchy</span></a></h3><p>DataFlex adopts a modular design with the following layers:</p><ol><li><strong>Base Layer (LlamaFactory)</strong>: Provides model management, data processing, optimizers and other basic components</li><li><strong>Trainer Layer (DataFlex Trainers)</strong>: <strong>Replaces</strong> LlamaFactory&#39;s original trainer, implementing three dynamic training modes</li><li><strong>Strategy Component Layer (Components)</strong>: Provides specific data processing strategies (Selector/Mixer/Weighter)</li><li><strong>Registry System</strong>: Manages component registration and loading</li></ol><p><strong>Key Feature</strong>: DataFlex doesn&#39;t add new layers on top of LlamaFactory, but <strong>seamlessly replaces</strong> its training layer, maintaining original functionality while enhancing training capabilities.</p><h2 id="three-core-trainer-concepts" tabindex="-1"><a class="header-anchor" href="#three-core-trainer-concepts"><span>Three Core Trainer Concepts</span></a></h2><p>DataFlex provides three core trainers that can seamlessly integrate into LlamaFactory&#39;s training pipeline:</p><ul><li><strong>Select Trainer (Dynamic Selection Trainer)</strong>: During training, dynamically selects a subset of samples from the dataset based on predefined strategies (Selector) for subsequent training, e.g., prioritizing &quot;difficult&quot; samples that the model finds challenging.</li><li><strong>Mix Trainer (Dynamic Ratio Trainer)</strong>: Supports dynamic adjustment of mixing ratios for data from different sources or domains during training.</li><li><strong>Weight Trainer (Dynamic Weighting Trainer)</strong>: Supports dynamic adjustment of sample weights during backpropagation, increasing learning intensity for model-preferred data.</li></ul><h2 id="usage-example" tabindex="-1"><a class="header-anchor" href="#usage-example"><span>Usage Example</span></a></h2><p>The training command is very similar to LlamaFactory. Below is an example using LESS, refer to the paper for details <a href="https://arxiv.org/abs/2402.04333" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2402.04333</a>:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">FORCE_TORCHRUN</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">1</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> DISABLE_VERSION_CHECK</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">1</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> dataflex-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/selectors/less.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>Note</strong>: Unlike standard LlamaFactory, your <code>.yaml</code> configuration file must include DataFlex-specific parameters in addition to LlamaFactory&#39;s standard training parameters.</p><h2 id="integration-with-llamafactory" tabindex="-1"><a class="header-anchor" href="#integration-with-llamafactory"><span>Integration with LlamaFactory</span></a></h2><p>DataFlex is fully compatible with LlamaFactory&#39;s configuration and usage:</p><ol><li><strong>Configuration Compatibility</strong>: Add DataFlex parameters on top of LlamaFactory configuration</li><li><strong>Consistent Commands</strong>: Use <code>dataflex-cli</code> instead of <code>llamafactory-cli</code></li><li><strong>Feature Preservation</strong>: Supports all original LlamaFactory functionality</li><li><strong>Seamless Switching</strong>: Can fallback to original training mode with <code>train_type: static</code></li></ol><p>This design ensures users can progressively adopt DataFlex functionality without major modifications to existing workflows.</p>`,22)])])}const c=e(r,[["render",t]]),p=JSON.parse('{"path":"/en/guide/basicinfo/framework/","title":"Framework Design","lang":"en-US","frontmatter":{"title":"Framework Design","icon":"material-symbols:auto-transmission-sharp","createTime":"2025/06/13 14:59:56","permalink":"/en/guide/basicinfo/framework/"},"readingTime":{"minutes":1.59,"words":476},"git":{"createdTime":1758865024000,"updatedTime":1759047473000,"contributors":[{"name":"Hao Liang","username":"","email":"hao.liang@stu.pku.edu.cn","commits":3,"avatar":"https://gravatar.com/avatar/105bae3e8661728b9f2f5440992b04f5f28459b66a049d09b52213ce1438f6bc?d=retro"},{"name":"zzy1127","username":"zzy1127","email":"67784246+zzy1127@users.noreply.github.com","commits":1,"avatar":"https://avatars.githubusercontent.com/zzy1127?v=4","url":"https://github.com/zzy1127"}]},"filePathRelative":"en/notes/guide/basicinfo/framework.md","headers":[]}');export{c as comp,p as data};

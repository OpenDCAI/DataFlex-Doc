import{_ as e,c as n,a as i,o as s}from"./app-Bgn5Gxg-.js";const r={};function t(o,a){return s(),n("div",null,[...a[0]||(a[0]=[i(`<h2 id="overview" tabindex="-1"><a class="header-anchor" href="#overview"><span>Overview</span></a></h2><p>DataFlex is an advanced dynamic training framework built on <a href="https://github.com/hiyouga/LLaMA-Factory" target="_blank" rel="noopener noreferrer">LlamaFactory</a>. It intelligently schedules data during training, supporting <strong>dynamic sample selection</strong>, <strong>domain ratio adjustment</strong>, and <strong>dynamic weight allocation</strong> to improve training efficiency and final model performance.</p><h3 id="design-philosophy" tabindex="-1"><a class="header-anchor" href="#design-philosophy"><span>Design Philosophy</span></a></h3><p>The core design philosophy of DataFlex is: <strong>Data-centric intelligent training scheduling</strong>. Traditional training methods typically use fixed data order and ratios, while DataFlex allows models to dynamically adjust data usage strategies based on their current state during training, achieving more efficient learning. It is designed to seamlessly integrate with LlamaFactory, providing researchers and developers with more flexible and powerful training control capabilities.</p><p>During the data selection process, it is often necessary to perform operations such as embedding, inference, and gradient computation on data samples. DataFlex is designed to provide a unified management framework for embedding, large model inference, and gradient computation.</p><h2 id="core-architecture" tabindex="-1"><a class="header-anchor" href="#core-architecture"><span>Core Architecture</span></a></h2><h3 id="overall-architecture-diagram" tabindex="-1"><a class="header-anchor" href="#overall-architecture-diagram"><span>Overall Architecture Diagram</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-"><span class="line"><span>┌───────────────────────────────────────────────────────────────────────────────┐</span></span>
<span class="line"><span>│                           LlamaFactory Framework                              │</span></span>
<span class="line"><span>├───────────────────────────────────────────────────────────────────────────────┤</span></span>
<span class="line"><span>│                  Model Management · Data Processing · Optimizers              │</span></span>
<span class="line"><span>├───────────────────────────────────────────────────────────────────────────────┤</span></span>
<span class="line"><span>│            Training Layer (DataFlex replaces LlamaFactory trainer)            │</span></span>
<span class="line"><span>│  ┌────────────────────────┬────────────────────────┬────────────────────────┐ │</span></span>
<span class="line"><span>│  │      Select Trainer    │       Mix Trainer      │     Weight Trainer     │ │</span></span>
<span class="line"><span>│  │   (Dynamic Selection)  │      (Dynamic Ratio)   │     (Dynamic Weights)  │ │</span></span>
<span class="line"><span>│  ├────────────────────────┼────────────────────────┼────────────────────────┤ │</span></span>
<span class="line"><span>│  │  Selector Components   │    Mixer Components    │   Weighter Components  │ │</span></span>
<span class="line"><span>│  │  ┌──────────────────┐  │  ┌──────────────────┐  │  ┌───────────────────┐ │ │</span></span>
<span class="line"><span>│  │  │  Loss Selector   │  │  │   Random Mixer   │  │  │   Loss Weighter   │ │ │</span></span>
<span class="line"><span>│  │  │  LESS Selector   │  │  │   Custom Mixer   │  │  │  Custom Weighter  │ │ │</span></span>
<span class="line"><span>│  │  │   Custom ...     │  │  │       ...        │  │  │        ...        │ │ │</span></span>
<span class="line"><span>│  │  └──────────────────┘  │  └──────────────────┘  │  └───────────────────┘ │ │</span></span>
<span class="line"><span>│  └────────────────────────┴────────────────────────┴────────────────────────┘ │</span></span>
<span class="line"><span>└───────────────────────────────────────────────────────────────────────────────┘</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="component-hierarchy" tabindex="-1"><a class="header-anchor" href="#component-hierarchy"><span>Component Hierarchy</span></a></h3><p>DataFlex adopts a modular design with the following layers:</p><ol><li><strong>Base Layer (LlamaFactory)</strong>: Provides model management, data processing, optimizers and other basic components</li><li><strong>Trainer Layer (DataFlex Trainers)</strong>: <strong>Replaces</strong> LlamaFactory&#39;s original trainer, implementing three dynamic training modes</li><li><strong>Strategy Component Layer (Components)</strong>: Provides specific data processing strategies (Selector/Mixer/Weighter)</li><li><strong>Registry System</strong>: Manages component registration and loading</li></ol><p><strong>Key Feature</strong>: DataFlex doesn&#39;t add new layers on top of LlamaFactory, but <strong>seamlessly replaces</strong> its training layer, maintaining original functionality while enhancing training capabilities.</p><h2 id="three-core-trainer-concepts" tabindex="-1"><a class="header-anchor" href="#three-core-trainer-concepts"><span>Three Core Trainer Concepts</span></a></h2><p>DataFlex provides three core trainers that can seamlessly integrate into LlamaFactory&#39;s training pipeline:</p><ul><li><strong>Select Trainer (Dynamic Selection Trainer)</strong>: During training, dynamically selects a subset of samples from the dataset based on predefined strategies (Selector) for subsequent training, e.g., prioritizing &quot;difficult&quot; samples that the model finds challenging.</li><li><strong>Mix Trainer (Dynamic Ratio Trainer)</strong>: Supports dynamic adjustment of mixing ratios for data from different sources or domains during training.</li><li><strong>Weight Trainer (Dynamic Weighting Trainer)</strong>: Supports dynamic adjustment of sample weights during backpropagation, increasing learning intensity for model-preferred data.</li></ul>`,15)])])}const c=e(r,[["render",t]]),d=JSON.parse('{"path":"/en/guide/basicinfo/framework/","title":"Framework Design","lang":"en-US","frontmatter":{"title":"Framework Design","icon":"material-symbols:auto-transmission-sharp","createTime":"2025/06/13 14:59:56","permalink":"/en/guide/basicinfo/framework/"},"readingTime":{"minutes":1.3,"words":390},"git":{"createdTime":1758865024000,"updatedTime":1762183872000,"contributors":[{"name":"Hao Liang","username":"","email":"hao.liang@stu.pku.edu.cn","commits":4,"avatar":"https://gravatar.com/avatar/105bae3e8661728b9f2f5440992b04f5f28459b66a049d09b52213ce1438f6bc?d=retro"},{"name":"zzy1127","username":"zzy1127","email":"67784246+zzy1127@users.noreply.github.com","commits":1,"avatar":"https://avatars.githubusercontent.com/zzy1127?v=4","url":"https://github.com/zzy1127"}]},"filePathRelative":"en/notes/guide/basicinfo/framework.md","headers":[]}');export{c as comp,d as data};

import{_ as t,c as a,a as n,o as i}from"./app-Bgn5Gxg-.js";const r={};function o(s,e){return i(),a("div",null,[...e[0]||(e[0]=[n('<p>In recent years, the development of large models has largely depended on large-scale, high-quality training data. First, the preparation of high-quality datasets is crucial, a process completed by our other project <a href="https://github.com/OpenDCAI/DataFlow/tree/main" target="_blank" rel="noopener noreferrer">DataFlow</a>. Building on this foundation, the interaction between data and models during training is equally important, such as data selection, mixing, and weighting throughout the training process. Although several influence-based methods have been proposed in academia — such as those based on the distributional distance between training and test data, as well as strategies like TracIn, Influence Function, and PMP — there still lacks a unified, user-friendly, and extensible training framework.</p><p>To address this problem, we built <a href="https://github.com/OpenDCAI/DataFlex/tree/main" target="_blank" rel="noopener noreferrer">DataFlex</a> based on <a href="https://github.com/hiyouga/LLaMA-Factory" target="_blank" rel="noopener noreferrer">LLaMA-Factory</a>, a data-centric system focused on optimizing data-model interactions during training, combining both <strong>ease of use</strong> and <strong>training effectiveness</strong>.</p><h2 id="dataflex-a-data-centric-model-training-system" tabindex="-1"><a class="header-anchor" href="#dataflex-a-data-centric-model-training-system"><span>DataFlex: A Data-Centric Model Training System</span></a></h2><p><a href="https://github.com/OpenDCAI/DataFlex/tree/main" target="_blank" rel="noopener noreferrer">DataFlex</a> provides the following three core functionalities during training:</p><p><strong>1. Data Selection</strong> Dynamically select the most beneficial data for the current training step to improve training efficiency and model performance.</p><p><strong>2. Data Ratio Adjustment</strong> In multi-domain data training, support various mainstream data proportion mixing methods for flexible control of data distribution across different domains.</p><p><strong>3. Data Weight Allocation</strong> Calculate the contribution of each sample in a batch to the model and assign differentiated weights to different data points to achieve better training results.</p>',7)])])}const d=t(r,[["render",o]]),c=JSON.parse('{"path":"/en/guide/intro/basicinfo/intro/","title":"Introduction","lang":"en-US","frontmatter":{"title":"Introduction","icon":"mdi:tooltip-text-outline","createTime":"2025/06/13 14:51:34","permalink":"/en/guide/intro/basicinfo/intro/"},"readingTime":{"minutes":0.84,"words":253},"git":{"createdTime":1758865024000,"updatedTime":1762183872000,"contributors":[{"name":"Hao Liang","username":"","email":"hao.liang@stu.pku.edu.cn","commits":2,"avatar":"https://gravatar.com/avatar/105bae3e8661728b9f2f5440992b04f5f28459b66a049d09b52213ce1438f6bc?d=retro"},{"name":"zzy1127","username":"zzy1127","email":"67784246+zzy1127@users.noreply.github.com","commits":1,"avatar":"https://avatars.githubusercontent.com/zzy1127?v=4","url":"https://github.com/zzy1127"}]},"filePathRelative":"en/notes/guide/basicinfo/intro.md","headers":[]}');export{d as comp,c as data};
